{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
      "metadata": {
        "id": "efad6479-7fb1-40c4-8610-8963f8de307f"
      },
      "source": [
        "# Lab | Agent & Vector store\n",
        "\n",
        "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
        "\n",
        "# Shakespeare "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3dbbae",
      "metadata": {},
      "source": [
        "# 🎯 What's the goal of this lab?\n",
        "Basically, we’re learning how to make an AI agent that can talk to data\n",
        "\n",
        "We do this by:\n",
        "\n",
        "Loading some text (like Shakespeare sonnets or State of the Union speeches),\n",
        "\n",
        "Splitting it into chunks, embedding it,\n",
        "\n",
        "Storing those chunks in a vector database (so we can search it smartly),\n",
        "\n",
        "And finally creating an agent that uses the vector DB to answer our questions like a brainy assistant.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b22020a",
      "metadata": {
        "id": "9b22020a"
      },
      "source": [
        "## Create the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
        "outputId": "f6df2a4b-737f-4702-dceb-72deeb01683c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install chromadb langchain langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85096cde",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
      "metadata": {
        "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5ec27f",
      "metadata": {},
      "source": [
        "#  Load .env file to get API keys securely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
      "metadata": {
        "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5905f4b",
      "metadata": {},
      "source": [
        "# Initialize the LLM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
      "metadata": {
        "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f6dd113",
      "metadata": {},
      "source": [
        "# This code is dynamic—it automatically finds the right folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7b772b",
      "metadata": {
        "id": "0b7b772b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pathlib import Path #Path is from Python’s built-in \n",
        "\n",
        "relevant_parts = []\n",
        "for p in Path(\".\").absolute().parts:\n",
        "    relevant_parts.append(p)\n",
        "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
        "        break\n",
        "doc_path = str(Path(*relevant_parts) / \"sonnets.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2675861",
      "metadata": {
        "id": "f2675861",
        "tags": []
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"shakespeare_sonnets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc8035f",
      "metadata": {},
      "source": [
        "- RetrievalQA is:\n",
        "A ready-made pipeline that:\n",
        "\n",
        "Retrieves relevant chunks using smart search (semantic search via docsearch).\n",
        "\n",
        "Feeds those chunks into an LLM.\n",
        "\n",
        "Returns a nice, natural language answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5403d4",
      "metadata": {
        "id": "bc5403d4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sonnets = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8efc234",
      "metadata": {},
      "source": [
        "- Other options:\n",
        "\n",
        "\"map_reduce\" – processes each chunk individually, then combines answers.\n",
        "\n",
        "\"refine\" – refines the answer step-by-step with each chunk.\n",
        "\n",
        "\"map_rerank\" – scores answers and picks the best.\n",
        "\n",
        "stuff for text isnt huge "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1431cded",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1431cded",
        "outputId": "b878ebdb-0683-4332-cc4b-a1e983450ea7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915d3ff3",
      "metadata": {
        "id": "915d3ff3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96a2edf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96a2edf8",
        "outputId": "37530705-79ac-437c-cac4-5d23b29b0f3e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "docs = loader.load()\n",
        "ruff_texts = text_splitter.split_documents(docs)\n",
        "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
        "ruff = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6c031",
      "metadata": {
        "id": "c0a6c031"
      },
      "source": [
        "## Create the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb142786",
      "metadata": {
        "id": "eb142786",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20ee8191",
      "metadata": {},
      "source": [
        "# 💥 Building a multi-tool AI agent - 2 tools below "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850bc4e9",
      "metadata": {
        "id": "850bc4e9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Shakespeare QA System\",\n",
        "        func=sonnets.run,  # Make sure this matches your RetrievalQA object\n",
        "        description=\"Useful for answering questions about Shakespeare's sonnets, such as themes, metaphors, and interpretations. Input should be a fully formed question like 'What is the theme of Sonnet 18?'\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"Useful for answering questions about Ruff (a Python linter), including features, rules, and behavior. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc47f230",
      "metadata": {
        "id": "fc47f230",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Construct the agent (uses ZERO_SHOT_REACT_DESCRIPTION by default)\n",
        "\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True # see how it thinks - a full play-by-play.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75sW6eYpju6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c75sW6eYpju6",
        "outputId": "fbf51622-0585-408b-b147-41c0e4f5f1f6"
      },
      "outputs": [],
      "source": [
        "print(OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xrw0HYjZoaqS",
      "metadata": {
        "id": "xrw0HYjZoaqS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"k-proj-QOapNUasNeC59V3D7qaH4Vp1xznP8_0iYZeBZ7u712x-BeuuJGsUiSNYAZSHpxVBdd-Info83pT3BlbkFJp0oiLWHjAgy8N2bQUOAPR_3gC4qfnPube9qBiigS1OTcdJAgDdIoI4NP5qp9iP0wLeiPb33O8A\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "208e8f27",
      "metadata": {},
      "source": [
        "- sends question to the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ca2db8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ca2db8",
        "outputId": "94c0e02e-4b7f-4fb6-f22f-663da2628e69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.invoke(\n",
        "    \"what poem in shakspaer is very popular?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e91b811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e91b811",
        "outputId": "0fd91140-6b57-4f1c-931b-f4dfcb2edcc9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787a9b5e",
      "metadata": {
        "id": "787a9b5e"
      },
      "source": [
        "## Use the Agent solely as a router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9161ba91",
      "metadata": {
        "id": "9161ba91"
      },
      "source": [
        "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
        "\n",
        "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f59b377e",
      "metadata": {
        "id": "f59b377e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Shakespeare QA System\",\n",
        "        func=sonnets.run,  # Make sure this matches your RetrievalQA object\n",
        "        description=\"Useful for answering questions about Shakespeare's sonnets, such as themes, metaphors, and interpretations. Input should be a fully formed question like 'What is the theme of Sonnet 18?'\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"Useful for answering questions about Ruff (a Python linter), including features, rules, and behavior. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "#return_direct=True\n",
        "#eyo agent, don’t overthink it. Just run this tool and return whatever it gives you directly. No more thought chains, no commentary — just the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8615707a",
      "metadata": {
        "id": "8615707a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfd0a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edfd0a1a",
        "outputId": "94418e31-2c03-4562-9f0d-11008a8feb91",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a0cbbe",
      "metadata": {
        "id": "49a0cbbe"
      },
      "source": [
        "## Vector Stores Work So Well Here\n",
        "## Multi-Hop vector store reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "844322b3",
      "metadata": {},
      "source": [
        "- giving the agent a complex question that requires multiple facts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d397a233",
      "metadata": {
        "id": "d397a233",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Shakespeare QA System\",\n",
        "        func=sonnets.run, \n",
        "        description=\"Useful for answering questions about Shakespeare's sonnets, such as themes, metaphors, and interpretations. Input should be a fully formed question like 'What is the theme of Sonnet 18?'\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"Useful for answering questions about Ruff (a Python linter), including features, rules, and behavior. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06157240",
      "metadata": {
        "id": "06157240",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b492b520",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b492b520",
        "outputId": "4713b053-e752-4037-ad65-52299be5f768",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.invoke(\"Compare what Shakespeare says about eternal love in Sonnet 18 and Sonnet 116. Are their views aligned?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb85680",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.invoke(\"What are two different views on time from Shakespeare's sonnets, and which one presents a more optimistic view?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070cd0d2",
      "metadata": {},
      "source": [
        "# 🛠️ TOOLS BUILT in this NoteBook\n",
        "\n",
        "\n",
        " Shakespeare QA System\tsonnets.txt (via TextLoader)\t\n",
        "\n",
        " \n",
        " Ruff QA System\tRuff docs (via WebBaseLoader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fbc5682",
      "metadata": {},
      "source": [
        "# 💬 TYPES OF QUESTIONS HANDLED\n",
        " 1- ❓ Single-hop:\n",
        "\n",
        "\"What is Sonnet 18 about?\"\n",
        "\n",
        "2- 🔁 Multi-hop:\n",
        "\n",
        "\"How does Sonnet 18’s message about love compare to Sonnet 116?\"\n",
        "\n",
        "3- 🤖 Agent routing:\n",
        "\n",
        "\"What is Ruff’s default behavior for unused imports?\"\n",
        "(agent knows to use Ruff tool)\n",
        "\n",
        "🧪 Direct tool response:\n",
        "\n",
        "Using return_direct=True to skip extra agent logic"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
      "metadata": {
        "id": "efad6479-7fb1-40c4-8610-8963f8de307f"
      },
      "source": [
        "# Lab | Agent & Vector store\n",
        "\n",
        "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
        "\n",
        "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b24990",
      "metadata": {
        "id": "68b24990"
      },
      "source": [
        "# Combine agents and vector stores\n",
        "\n",
        "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
        "\n",
        "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b22020a",
      "metadata": {
        "id": "9b22020a"
      },
      "source": [
        "## Create the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
        "outputId": "aa3fb57d-bdd9-4b7f-9f8b-2be92a3eba89",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.72.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb langchain langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
      "metadata": {
        "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
      "metadata": {
        "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b7b772b",
      "metadata": {
        "id": "0b7b772b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "relevant_parts = []\n",
        "for p in Path(\".\").absolute().parts:\n",
        "    relevant_parts.append(p)\n",
        "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
        "        break\n",
        "doc_path = str(Path(*relevant_parts) / \"sonnets.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f2675861",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2675861",
        "outputId": "9ebc5ec0-c688-4954-c25a-14a88f053628",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 590, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 625, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 587, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 646, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 619, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 624, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 672, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 626, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 604, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 619, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 601, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 645, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 622, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 633, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 654, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 599, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 620, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 641, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 589, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 601, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 639, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 630, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 598, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 635, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 612, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 634, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 588, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 598, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 585, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 618, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 636, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 643, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 626, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 596, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 606, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 624, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 604, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 625, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 583, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 619, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 616, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 625, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 618, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 602, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 570, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 599, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 632, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 572, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 574, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 670, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 608, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 594, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 601, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 637, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 593, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 593, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 580, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 619, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 569, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 587, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 596, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 628, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 604, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 602, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 640, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 603, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 632, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 611, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 583, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 627, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 615, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 624, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 615, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 665, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 623, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 592, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 634, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 593, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 642, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 595, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 598, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 595, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 597, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 596, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 608, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 640, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 583, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 595, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 612, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 569, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 596, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 620, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 590, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 546, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 618, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 623, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 597, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 611, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 596, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 627, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 589, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 629, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 640, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 621, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 613, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 631, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 575, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 506, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 617, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 597, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 629, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 581, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 608, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 635, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 614, which is longer than the specified 500\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"sonnets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bc5403d4",
      "metadata": {
        "id": "bc5403d4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_of_union = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1431cded",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1431cded",
        "outputId": "6ade7cc4-2b7e-4631-9d29-b0acd1f0a45d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "915d3ff3",
      "metadata": {
        "id": "915d3ff3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "96a2edf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96a2edf8",
        "outputId": "dfd5d924-6a79-4190-c18d-b022c3e476dd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2122, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 787, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3187, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 721, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1017, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 820, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 657, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 809, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 717, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 798, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1256, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2321, which is longer than the specified 500\n"
          ]
        }
      ],
      "source": [
        "docs = loader.load()\n",
        "ruff_texts = text_splitter.split_documents(docs)\n",
        "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
        "ruff = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6c031",
      "metadata": {
        "id": "c0a6c031"
      },
      "source": [
        "## Create the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eb142786",
      "metadata": {
        "id": "eb142786",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "850bc4e9",
      "metadata": {
        "id": "850bc4e9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Sonnets QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare's sonnets. Input should be a fully formed question.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fc47f230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc47f230",
        "outputId": "f503bdd5-ef44-42bf-8e03-7d46eef9dd39",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-5458be099bf6>:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "kGXwcpLA0e1D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGXwcpLA0e1D",
        "outputId": "971caad9-cced-4948-ec1c-1e77c4ecef6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to find the best match.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"Which sonnet has the theme of love?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The sonnet that has the theme of love is Sonnet 30.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to find out why Sonnet 30 is the best match.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"Why is Sonnet 30 the best match for the theme of love?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Sonnet 30 is the best match for the theme of love because it explores the enduring nature of love and how it transcends time and change. The speaker reflects on how their love remains constant and unchanging, even as they grow older and face challenges. This theme of eternal love is a central aspect of the concept of love and is beautifully expressed in Sonnet 30.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Sonnet 30 is the best match for the theme of love because it explores the enduring nature of love and how it transcends time and change.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Given the theme \"love\", which sonnet best matches this topic and why?',\n",
              " 'output': 'Sonnet 30 is the best match for the theme of love because it explores the enduring nature of love and how it transcends time and change.'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    'Given the theme \"love\", which sonnet best matches this topic and why?'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "10ca2db8",
      "metadata": {
        "id": "10ca2db8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# agent.invoke(\n",
        "#     \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4e91b811",
      "metadata": {
        "id": "4e91b811",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cHVTPbtr1r1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHVTPbtr1r1c",
        "outputId": "d201cb13-2633-4786-ef63-59ededed8d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"Who is the speaker addressing in Sonnet 18?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The speaker is addressing their love and expressing their devotion to them.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should now use the Ruff QA System to identify the speaker's tone in Sonnet 18.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What is the speaker's tone in Sonnet 18?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System again to find out the answer.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"What is the speaker's tone in Sonnet 18?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The speaker's tone in Sonnet 18 is admiring and reverent.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The speaker is addressing their love and expressing their devotion to them. The speaker's tone in Sonnet 18 is admiring and reverent.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Can you identify who the speaker is addressing in Sonnet 18?',\n",
              " 'output': \"The speaker is addressing their love and expressing their devotion to them. The speaker's tone in Sonnet 18 is admiring and reverent.\"}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"Can you identify who the speaker is addressing in Sonnet 18?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787a9b5e",
      "metadata": {
        "id": "787a9b5e"
      },
      "source": [
        "## Use the Agent solely as a router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9161ba91",
      "metadata": {
        "id": "9161ba91"
      },
      "source": [
        "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
        "\n",
        "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f59b377e",
      "metadata": {
        "id": "f59b377e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"sonnets QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare's sonnets. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8615707a",
      "metadata": {
        "id": "8615707a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "36e718a9",
      "metadata": {
        "id": "36e718a9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# agent.invoke(\n",
        "#     \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "edfd0a1a",
      "metadata": {
        "id": "edfd0a1a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "xPylfp9LGc3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPylfp9LGc3e",
        "outputId": "92461a28-f8f0-4e00-a6e3-3fd52e90b29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnet QA System to find the answer.\n",
            "Action: Sonnet QA System\n",
            "Action Input: \"What does Sonnet 18 say about the permanence of beauty?\"\u001b[0m\n",
            "Observation: Sonnet QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the sonnets QA System to find the answer.\n",
            "Action: sonnets QA System\n",
            "Action Input: \"What does Sonnet 18 say about the permanence of beauty?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Sonnet 18 suggests that beauty is temporary and will eventually fade with time, but it can be preserved through art and writing. The speaker compares beauty to a flower that will eventually wither, but through his poetry, he can immortalize the beauty of his subject.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What does Sonnet 18 say about the permanence of beauty?',\n",
              " 'output': ' Sonnet 18 suggests that beauty is temporary and will eventually fade with time, but it can be preserved through art and writing. The speaker compares beauty to a flower that will eventually wither, but through his poetry, he can immortalize the beauty of his subject.'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"What does Sonnet 18 say about the permanence of beauty?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "V5_cGEMwGct1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5_cGEMwGct1",
        "outputId": "6b770cee-8954-414e-e2b9-f846d0214271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnet QA System to find the answer.\n",
            "Action: Sonnet QA System\n",
            "Action Input: \"What does Sonnet 18 say about the permanence of beauty?\"\u001b[0m\n",
            "Observation: Sonnet QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the sonnets QA System to find the answer.\n",
            "Action: sonnets QA System\n",
            "Action Input: \"What does Sonnet 18 say about the permanence of beauty?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Sonnet 18 suggests that beauty is temporary and will eventually fade with time, but it can be preserved through art and writing. The speaker compares beauty to a flower that will eventually wither, but through his poetry, he can immortalize the beauty of his subject.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What does Sonnet 18 say about the permanence of beauty?',\n",
              " 'output': ' Sonnet 18 suggests that beauty is temporary and will eventually fade with time, but it can be preserved through art and writing. The speaker compares beauty to a flower that will eventually wither, but through his poetry, he can immortalize the beauty of his subject.'}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"What does Sonnet 18 say about the permanence of beauty?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a0cbbe",
      "metadata": {
        "id": "49a0cbbe"
      },
      "source": [
        "## Multi-Hop vector store reasoning\n",
        "\n",
        "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d397a233",
      "metadata": {
        "id": "d397a233",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Sonnets QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare's sonnets. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "06157240",
      "metadata": {
        "id": "06157240",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b492b520",
      "metadata": {
        "id": "b492b520",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# agent.invoke(\n",
        "#     \"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "J7ha3Jo_G0E1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ha3Jo_G0E1",
        "outputId": "903b1ce5-0301-414f-8c8d-0fca8d334663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to find the sonnet that talks about aging or the loss of beauty.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"Which sonnet talks about aging or the loss of beauty?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Sonnet 2 talks about aging and the loss of beauty.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to check if there are any rules that could help enforce clean formatting in poetic lines.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"Does ruff have any rule that could help enforce clean formatting in such poetic lines?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m No, Ruff does not have any specific rules for enforcing clean formatting in poetic lines. Ruff is primarily designed for linting and formatting Python code, so it may not be the best tool for this specific use case. You may want to consider using a different tool or manually enforcing formatting in your poetic lines.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Sonnet 2 talks about aging and the loss of beauty, and Ruff does not have any specific rules for enforcing clean formatting in poetic lines.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Which sonnet talks about aging or the loss of beauty? Does ruff have any rule that could help enforce clean formatting in such poetic lines?',\n",
              " 'output': 'Sonnet 2 talks about aging and the loss of beauty, and Ruff does not have any specific rules for enforcing clean formatting in poetic lines.'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"Which sonnet talks about aging or the loss of beauty? Does ruff have any rule that could help enforce clean formatting in such poetic lines?\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

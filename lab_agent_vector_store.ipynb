{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
      "metadata": {
        "id": "efad6479-7fb1-40c4-8610-8963f8de307f"
      },
      "source": [
        "# Lab | Agent & Vector store\n",
        "\n",
        "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
        "\n",
        "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b24990",
      "metadata": {
        "id": "68b24990"
      },
      "source": [
        "# Combine agents and vector stores\n",
        "\n",
        "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
        "\n",
        "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b22020a",
      "metadata": {
        "id": "9b22020a"
      },
      "source": [
        "## Create the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
        "outputId": "def73f47-d05c-4d40-ed93-6d8b168ff5d7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.72.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.19.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb langchain langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
      "metadata": {
        "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
        "outputId": "833922d4-6d3b-470c-c1f4-a72cce202f48",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:dotenv.main:python-dotenv could not parse statement starting at line 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
      "metadata": {
        "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0b7b772b",
      "metadata": {
        "id": "0b7b772b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "relevant_parts = []\n",
        "for p in Path(\".\").absolute().parts:\n",
        "    relevant_parts.append(p)\n",
        "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
        "        break\n",
        "doc_path = str(Path(*relevant_parts) / \"hamlet.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f2675861",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2675861",
        "outputId": "81a59b77-63bb-420d-8a50-df2b15e6a0f0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1251, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1743, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1361, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1400, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1511, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1227, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1102, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2077, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1527, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1277, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2481, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1529, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1022, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1441, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1327, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1616, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1003, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1568, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1509, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1070, which is longer than the specified 1000\n",
            "WARNING:dotenv.main:python-dotenv could not parse statement starting at line 2\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"hamlet\", persist_directory=\"./chroma_db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "bc5403d4",
      "metadata": {
        "id": "bc5403d4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_of_union = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1431cded",
      "metadata": {
        "id": "1431cded",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "915d3ff3",
      "metadata": {
        "id": "915d3ff3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "96a2edf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96a2edf8",
        "outputId": "b6fc5d46-2316-4a32-c372-1d447ce9132a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2122, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3187, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1017, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1256, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2321, which is longer than the specified 1000\n",
            "WARNING:dotenv.main:python-dotenv could not parse statement starting at line 2\n"
          ]
        }
      ],
      "source": [
        "docs = loader.load()\n",
        "docs = loader.load()\n",
        "ruff_texts = text_splitter.split_documents(docs)\n",
        "persist_directory=\"./chroma_db\"\n",
        "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\", persist_directory=persist_directory)\n",
        "ruff = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6c031",
      "metadata": {
        "id": "c0a6c031"
      },
      "source": [
        "## Create the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "eb142786",
      "metadata": {
        "id": "eb142786",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "850bc4e9",
      "metadata": {
        "id": "850bc4e9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"hamlet QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about the most recent hamlet address. Input should be a fully formed question.\",\n",
        "        return_direct=True,  # Add return_direct=True\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "        return_direct=True,  # Add return_direct=True\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "fc47f230",
      "metadata": {
        "id": "fc47f230",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "10ca2db8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ca2db8",
        "outputId": "2ea51388-ae03-4d15-89ce-ae5ccf799b57",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the hamlet QA System to answer this question since it is related to the play Hamlet.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"What does the Ghost say about his brother’s role in his death?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The Ghost reveals that his brother, now the current king, is the one who murdered him.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What does the Ghost say about his brother’s role in his death?',\n",
              " 'output': ' The Ghost reveals that his brother, now the current king, is the one who murdered him.'}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"What does the Ghost say about his brother’s role in his death?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "4e91b811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e91b811",
        "outputId": "9ac4fcfe-4718-4d5c-e8a5-2563ae574332",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Hamlet's initial reaction is important to understanding his character and motivations.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"How does Hamlet initially react to the news of his father's murder?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Hamlet is shocked and overwhelmed by the news of his father's murder. He exclaims \"O God!\" and \"Murder!\" upon hearing it from the Ghost. He also immediately expresses a desire for revenge, saying \"Haste me to know't, that I, with wings as swift/As meditation or the thoughts of love,/May sweep to my revenge.\"\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': \"How does Hamlet initially react to the news of his father's murder?\",\n",
              " 'output': ' Hamlet is shocked and overwhelmed by the news of his father\\'s murder. He exclaims \"O God!\" and \"Murder!\" upon hearing it from the Ghost. He also immediately expresses a desire for revenge, saying \"Haste me to know\\'t, that I, with wings as swift/As meditation or the thoughts of love,/May sweep to my revenge.\"'}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"How does Hamlet initially react to the news of his father's murder?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787a9b5e",
      "metadata": {
        "id": "787a9b5e"
      },
      "source": [
        "## Use the Agent solely as a router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9161ba91",
      "metadata": {
        "id": "9161ba91"
      },
      "source": [
        "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
        "\n",
        "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f59b377e",
      "metadata": {
        "id": "f59b377e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"hamlet QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about the most recent hamlet address. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "8615707a",
      "metadata": {
        "id": "8615707a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "36e718a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36e718a9",
        "outputId": "eadd3fa4-7e5f-46dc-9d0d-626b25402f34",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Hamlet is a QA System, so it should be able to provide a detailed answer based on the text of the play.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"How does Hamlet respond to the Ghost’s call for revenge?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Hamlet responds with a sense of urgency and determination, stating that he will swiftly seek revenge. He also expresses his prophetic soul and realization that his uncle is the one who murdered his father.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'How does Hamlet respond to the Ghost’s call for revenge?',\n",
              " 'output': ' Hamlet responds with a sense of urgency and determination, stating that he will swiftly seek revenge. He also expresses his prophetic soul and realization that his uncle is the one who murdered his father.'}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"How does Hamlet respond to the Ghost’s call for revenge?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "edfd0a1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edfd0a1a",
        "outputId": "55a5ab0c-0471-486c-cb61-e7435ae0be5c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m The Ghost is a supernatural being, so its advice may not be reliable.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"What advice does the Ghost give Hamlet regarding his mother, Queen Gertrude?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The Ghost advises Hamlet to speak to his mother and try to intervene between her and her inner turmoil.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What advice does the Ghost give Hamlet regarding his mother, Queen Gertrude?',\n",
              " 'output': ' The Ghost advises Hamlet to speak to his mother and try to intervene between her and her inner turmoil.'}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"What advice does the Ghost give Hamlet regarding his mother, Queen Gertrude?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a0cbbe",
      "metadata": {
        "id": "49a0cbbe"
      },
      "source": [
        "## Multi-Hop vector store reasoning\n",
        "\n",
        "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "d397a233",
      "metadata": {
        "id": "d397a233",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"hamlet QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about the most recent hamlet address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "06157240",
      "metadata": {
        "id": "06157240",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "b492b520",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b492b520",
        "outputId": "df294072-8070-4bab-a278-e9be9fa76d59",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m They must have noticed some unusual behavior from Hamlet.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"Why do Horatio and Marcellus become concerned about Hamlet’s state of mind?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Horatio and Marcellus become concerned about Hamlet's state of mind because he is speaking to a ghost and seems to be in a state of shock and confusion. They are worried about his mental well-being and want to make sure he is okay.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This could be a sign of something more serious going on with Hamlet.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"What could be the cause of Hamlet's unusual behavior?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The cause of Hamlet's unusual behavior could be his grief over his father's death and his mother's hasty remarriage to his uncle, as well as his suspicions about his uncle's involvement in his father's death.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m It seems like there are a lot of factors contributing to Hamlet's state of mind.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"What other factors could be affecting Hamlet's mental state?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Other factors that could be affecting Hamlet's mental state include his grief over his father's death, his anger towards his uncle for marrying his mother, and his feelings of betrayal and confusion over his mother's actions. Additionally, the pressure and expectations placed on him as the prince of Denmark could also be contributing to his mental state.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m It's important for Horatio and Marcellus to keep an eye on Hamlet and offer support.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What can Horatio and Marcellus do to help Hamlet?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m It's important for Horatio and Marcellus to keep an eye on Hamlet and offer support.\n",
            "Action: hamlet QA System\n",
            "Action Input: \"What actions can Horatio and Marcellus take to support Hamlet?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Horatio and Marcellus can support Hamlet by informing him about the ghost of his father and helping him investigate the truth behind his father's death. They can also offer emotional support and advice to Hamlet as he navigates his grief and seeks revenge. Additionally, they can assist Hamlet in his plans to expose Claudius' guilt and reclaim his rightful place as heir to the throne.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Horatio and Marcellus become concerned about Hamlet's state of mind because of his unusual behavior, which could be caused by his grief, anger, and suspicions towards his uncle, as well as the pressure and expectations placed on him as the prince of Denmark. To help Hamlet, they can offer support and assistance in his quest for revenge and justice.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Why do Horatio and Marcellus become concerned about Hamlet’s state of mind?',\n",
              " 'output': \"Horatio and Marcellus become concerned about Hamlet's state of mind because of his unusual behavior, which could be caused by his grief, anger, and suspicions towards his uncle, as well as the pressure and expectations placed on him as the prince of Denmark. To help Hamlet, they can offer support and assistance in his quest for revenge and justice.\"}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"Why do Horatio and Marcellus become concerned about Hamlet’s state of mind?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "XQsfEn9zyw-G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQsfEn9zyw-G",
        "outputId": "3253ee1f-8ac0-4e39-c93a-b9db1a9ee1e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the hamlet QA System to answer this question.\n",
            "Action: hamlet QA System\n",
            "Action Input: How does Shakespeare use the Ghost as a symbol in this scene?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m In this scene, Shakespeare uses the Ghost as a symbol of the past and the truth. The Ghost represents the past because it is the spirit of Hamlet's father, who has been dead for some time. It also represents the truth because it reveals to Hamlet the true nature of his father's death and urges him to seek revenge. The Ghost's appearance also symbolizes the disruption and corruption in the state of Denmark, as it is a sign of the unrest caused by the murder of the king.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: In this scene, Shakespeare uses the Ghost as a symbol of the past, the truth, and the disruption and corruption in the state of Denmark.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'How does Shakespeare use the Ghost as a symbol in this scene?',\n",
              " 'output': 'In this scene, Shakespeare uses the Ghost as a symbol of the past, the truth, and the disruption and corruption in the state of Denmark.'}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"How does Shakespeare use the Ghost as a symbol in this scene?\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

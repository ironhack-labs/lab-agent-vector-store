{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
    "\n",
    "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.11.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: sympy in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.28.0)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.2-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "   ---------------------------------------- 0.0/611.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 611.1/611.1 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
      "Downloading bcrypt-4.2.1-cp39-abi3-win_amd64.whl (153 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
      "Downloading grpcio-1.70.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.20.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.3 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.3 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
      "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading watchfiles-1.0.4-cp310-cp310-win_amd64.whl (284 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-14.2-cp310-cp310-win_amd64.whl (164 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53885 sha256=11696e9140ba62f5797380b6a8921f4faea625a2d5e09ce33678e49c087a0558\n",
      "  Stored in directory: c:\\users\\larry\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, wrapt, websockets, websocket-client, tomli, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, importlib-metadata, httptools, grpcio, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, humanfriendly, googleapis-common-protos, deprecated, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.6.1\n",
      "    Uninstalling importlib_metadata-8.6.1:\n",
      "      Successfully uninstalled importlib_metadata-8.6.1\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 cachetools-5.5.1 chroma-hnswlib-0.7.6 chromadb-0.6.3 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.7 flatbuffers-25.1.24 google-auth-2.38.0 googleapis-common-protos-1.66.0 grpcio-1.70.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 importlib-resources-6.5.2 kubernetes-32.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.11.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 starlette-0.45.3 tomli-2.2.1 typer-0.15.1 uvicorn-0.34.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-14.2 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea31bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.16 (from langchain_community)\n",
      "  Downloading langchain-0.3.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.32 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.32-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\larry\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.16-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.32-py3-none-any.whl (412 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.31\n",
      "    Uninstalling langchain-core-0.3.31:\n",
      "      Successfully uninstalled langchain-core-0.3.31\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.15\n",
      "    Uninstalling langchain-0.3.15:\n",
      "      Successfully uninstalled langchain-0.3.15\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.16 langchain-core-0.3.32 langchain_community-0.3.16 marshmallow-3.26.0 mypy-extensions-1.0.0 pydantic-settings-2.7.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "doc_path = str(Path(*relevant_parts) / \"state_of_the_union.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2675861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f53c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# Varialbles verifications\n",
    "print(len(documents))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_of_union = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c56b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The speech praises the courage and determination of the Ukrainian people in defending their country against Russian aggression. It also mentions the support of the United States and other NATO countries in standing with Ukraine.\n"
     ]
    }
   ],
   "source": [
    "# System pre-check \n",
    "query = \"What does the speech say about Ukraine?\"\n",
    "response = state_of_union.invoke({\"query\": query})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0049a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c80a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the variable was set as expected\n",
    "print(os.getenv(\"USER_AGENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed428079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a3be84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2122, which is longer than the specified 1000\n",
      "Created a chunk of size 3187, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1256, which is longer than the specified 1000\n",
      "Created a chunk of size 1051, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
    "ruff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0a5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ruff is a tool that helps developers with linting and formatting their Python code. It can be used as a drop-in replacement for other popular tools like Flake8 and Black, and it also has its own linter and formatter. Ruff is designed to be easy to install and use, and it can be integrated with various editors and IDEs. It helps developers maintain consistent and high-quality code by flagging potential errors and enforcing style guidelines.\n"
     ]
    }
   ],
   "source": [
    "# Ruff system verification\n",
    "query = \"What is Ruff, and how does it help developers?\"\n",
    "response = ruff.invoke({\"query\": query})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larry\\AppData\\Local\\Temp\\ipykernel_32880\\1834837320.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to check the accuracy of this answer.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Is it true that Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try rephrasing the question to see if I can get a better answer.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What was Biden's statement about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden stated that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court, as one of our nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This seems like a more accurate answer.\n",
      "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \"Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff and flake8 are both python linters, so they have similar functions. However, there may be specific reasons why one is preferred over the other.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\n",
      "\n",
      "3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff re-implements some of the most popular Flake8 plugins natively, which means you don't have to install and configure multiple plugins to get the same functionality.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and user-friendly experience compared to Flake8, making it a popular choice for many developers.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, and native implementation of popular Flake8 plugins, making it a more comprehensive and user-friendly option compared to Flake8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': 'Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, and native implementation of popular Flake8 plugins, making it a more comprehensive and user-friendly option compared to Flake8.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a27cbf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get information about economic policies and Ruff QA System to improve code quality.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What does the State of the Union address say about economic policies?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions a new economic vision for America, with a focus on investing in America, educating Americans, and growing the workforce. It also discusses the importance of infrastructure and passing the Bipartisan Infrastructure Law. The address also mentions a plan to fight inflation, which includes cutting the cost of prescription drugs.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I have information about economic policies, I should use Ruff QA System to improve code quality.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"How could Ruff improve code quality in economic models?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff could improve code quality in economic models by providing a comprehensive set of rules and guidelines for writing clean and efficient code. This would help catch potential errors and improve the overall readability and maintainability of the code. Additionally, Ruff's ability to automatically fix certain lint violations could save time and effort for developers, allowing them to focus on more complex tasks. By implementing Ruff's rules and using its linter and formatter, economic models could become more reliable and accurate, leading to better decision-making and potentially improving the overall economic outcomes.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The State of the Union address discusses various economic policies, including investing in America, education, workforce growth, infrastructure, and fighting inflation. Ruff could improve code quality in economic models by providing rules and guidelines for clean and efficient code, as well as its linter and formatter tools to catch errors and improve readability and maintainability. This could lead to more reliable and accurate economic models and potentially better economic outcomes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say about economic policies, and how could Ruff improve code quality in economic models?',\n",
       " 'output': 'The State of the Union address discusses various economic policies, including investing in America, education, workforce growth, infrastructure, and fighting inflation. Ruff could improve code quality in economic models by providing rules and guidelines for clean and efficient code, as well as its linter and formatter tools to catch errors and improve readability and maintainability. This could lead to more reliable and accurate economic models and potentially better economic outcomes.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What does the State of the Union address say about economic policies, and how could Ruff improve code quality in economic models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b93d623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get information about the most recent address and then use Ruff QA System to see how it could improve health models.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What does the State of the Union address say about public health?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions the need to increase funding for prevention, treatment, and recovery for addiction, as well as addressing mental health issues, especially among children. It also mentions the impact of COVID-19 on the nation and the progress being made in fighting the pandemic.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I have information about public health from the State of Union address, I can use Ruff QA System to see how it could improve health models.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"How could Ruff improve health models to ensure better health services to americans?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know, as I am just a program and not capable of making suggestions or improvements. It would be best to consult with healthcare professionals and experts in the field for ideas and solutions.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The State of the Union address mentions the need for increased funding and addressing mental health issues, but it does not specifically mention Ruff or how it could improve health models. It would be best to consult with healthcare professionals and experts for ideas and solutions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say about public health, and how could Ruff improve health models to ensure better health services to americans?',\n",
       " 'output': 'The State of the Union address mentions the need for increased funding and addressing mental health issues, but it does not specifically mention Ruff or how it could improve health models. It would be best to consult with healthcare professionals and experts for ideas and solutions.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What does the State of the Union address say about public health, and how could Ruff improve health models to ensure better health services to americans?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53e6f1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get information about the public health section of the address, and then use Ruff QA System to see how it could improve code quality in government financial models.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What does the State of the Union address say about public health?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions the need to increase funding for prevention, treatment, and recovery for addiction, as well as addressing mental health issues, especially among children. It also mentions the impact of COVID-19 on the nation and the progress being made in fighting the pandemic.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I should use Ruff QA System to see how it could improve code quality in government financial models.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"How could Ruff improve code quality in government financial models?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff could improve code quality in government financial models by providing a comprehensive set of rules and guidelines for writing clean and efficient code. It could also automatically detect and fix common errors and inconsistencies, reducing the potential for human error. Additionally, Ruff's integration with popular code editors and its ability to work alongside type checkers could help catch and prevent potential issues before they become larger problems. Overall, Ruff could help ensure that government financial models are written in a consistent and high-quality manner, leading to more accurate and reliable results.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The State of the Union address highlights the importance of public health and the need for increased funding, while Ruff could improve code quality in government financial models by providing a set of rules and guidelines, detecting and fixing errors, and integrating with popular code editors and type checkers. This could ultimately lead to more accurate and reliable results and potentially increase funds availability for public health initiatives.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say about public health, and how could Ruff improve code quality in goverment financial models to increase funds availability to be assigned to public health?',\n",
       " 'output': 'The State of the Union address highlights the importance of public health and the need for increased funding, while Ruff could improve code quality in government financial models by providing a set of rules and guidelines, detecting and fixing errors, and integrating with popular code editors and type checkers. This could ultimately lead to more accurate and reliable results and potentially increase funds availability for public health initiatives.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What does the State of the Union address say about public health, and how could Ruff improve code quality in goverment financial models to increase funds availability to be assigned to public health?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dfd3a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get information about the nation's cybersecurity and Ruff QA System to detect vulnerabilities.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What does the State of the Union address say about the nation's cybersecurity?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address does not specifically mention cybersecurity, but it does mention the need to hold social media platforms accountable for their impact on children and the importance of investing in emerging technologies to compete with other countries. These issues are often connected to cybersecurity concerns.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Ruff QA System to detect vulnerabilities in the government's cybersecurity system.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"How can Ruff detect vulnerabilities in the government's cybersecurity system?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know. Ruff is a linter and code quality tool for Python, it is not designed to detect vulnerabilities in a government's cybersecurity system. It is important to use specialized tools and experts in the field of cybersecurity to properly assess and address any potential vulnerabilities.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The State of the Union address does not specifically mention cybersecurity, but it does highlight the importance of investing in emerging technologies and holding social media platforms accountable for their impact on children, which can be connected to cybersecurity concerns. Ruff is not a suitable tool for detecting vulnerabilities in a government's cybersecurity system. It is important to use specialized tools and experts in the field of cybersecurity for this task.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say the nation cybersecurity, and how can Ruff detect vulnerabilities in the goverment Cybersecurity system?',\n",
       " 'output': \"The State of the Union address does not specifically mention cybersecurity, but it does highlight the importance of investing in emerging technologies and holding social media platforms accountable for their impact on children, which can be connected to cybersecurity concerns. Ruff is not a suitable tool for detecting vulnerabilities in a government's cybersecurity system. It is important to use specialized tools and experts in the field of cybersecurity for this task.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What does the State of the Union address say the nation cybersecurity, and how can Ruff detect vulnerabilities in the goverment Cybersecurity system?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \" Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff and flake8 are both python linters, so they have similar functions. However, there may be specific reasons why one is preferred over the other.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\n",
      "\n",
      "3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff re-implements some of the most popular Flake8 plugins natively, which means you don't have to install and configure multiple plugins to get the same functionality.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and user-friendly experience compared to Flake8, making it a popular choice for many developers.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': \"\\nThere are a few reasons why someone might choose to use Ruff over Flake8:\\n\\n1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\\n\\n2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\\n\\n3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\\n\\n4. Native implementation of popular Flake8 plugins: Ruff re-implements some of the most popular Flake8 plugins natively, which means you don't have to install and configure multiple plugins to get the same functionality.\\n\\nOverall, Ruff offers a more comprehensive and user-friendly experience compared to Flake8, making it a popular choice for many developers.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c785cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to get information about economic policies and Ruff QA System to improve code quality.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What does the State of the Union address say about economic policies?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions a new economic vision for America, with a focus on investing in America, educating Americans, and growing the workforce. It also discusses the importance of infrastructure and passing the Bipartisan Infrastructure Law. The address also mentions a plan to fight inflation, which includes cutting the cost of prescription drugs.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say about economic policies, and how could Ruff improve code quality in economic models?',\n",
       " 'output': ' The State of the Union address mentions a new economic vision for America, with a focus on investing in America, educating Americans, and growing the workforce. It also discusses the importance of infrastructure and passing the Bipartisan Infrastructure Law. The address also mentions a plan to fight inflation, which includes cutting the cost of prescription drugs.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What does the State of the Union address say about economic policies, and how could Ruff improve code quality in economic models?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e758279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to answer the first part of the question, and the State of Union QA System to answer the second part.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why is Ruff a better choice than Flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff is a better choice than Flake8 because it implements more rules (over 800 compared to Flake8's ~409), has better compatibility with Black, and can automatically fix its own lint violations. Additionally, Ruff does not require the installation of Rust, making it more accessible for users.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why is Ruff a better choice than Flake8, and what does the State of the Union address say about economic policies?',\n",
       " 'output': \" Ruff is a better choice than Flake8 because it implements more rules (over 800 compared to Flake8's ~409), has better compatibility with Black, and can automatically fix its own lint violations. Additionally, Ruff does not require the installation of Rust, making it more accessible for users.\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why is Ruff a better choice than Flake8, and what does the State of the Union address say about economic policies?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should check both tools to see if they have any information on Jupyter Notebooks.\n",
      "Action: Ruff QA System\n",
      "Action Input: What tool does ruff use to run over Jupyter Notebooks?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff does not currently have a specific tool for running over Jupyter Notebooks. However, it is possible to use Ruff with Jupyter Notebooks by converting the notebook to a Python script and then running Ruff on the script.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should also check the state of the union address to see if the president mentioned any tools related to Jupyter Notebooks.\n",
      "Action: State of Union QA System\n",
      "Action Input: Did the president mention any tools related to Jupyter Notebooks in the state of the union?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m No, the president did not mention any tools related to Jupyter Notebooks in the state of the union.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The president did not mention any tools related to Jupyter Notebooks in the state of the union.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?',\n",
       " 'output': 'The president did not mention any tools related to Jupyter Notebooks in the state of the union.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dbacb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m It's important to understand the context of the question before choosing which tool to use.\n",
      "Action: State of Union QA System\n",
      "Action Input: What does the State of the Union address say about climate change?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions the need to withstand the devastating effects of the climate crisis and promote environmental justice. It also mentions plans to build a national network of electric vehicle charging stations and replace lead pipes for clean water.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that I have the context of the question, I can use Ruff to help detect inefficiencies in the code of climate models.\n",
      "Action: Ruff QA System\n",
      "Action Input: How could Ruff help detect inefficiencies in the code of climate models?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff could help detect inefficiencies in the code of climate models by flagging any violations of coding best practices and style guidelines. This could include identifying unused imports, unnecessary code duplication, and other potential sources of inefficiency. Additionally, Ruff's linter could also catch any potential errors or bugs in the code, helping to ensure the accuracy and reliability of the climate model.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The State of the Union address mentions the need to address climate change and promote environmental justice, while Ruff could help detect inefficiencies in the code of climate models by flagging violations of coding best practices and catching potential errors or bugs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the State of the Union address say about climate change? How could Ruff help detect inefficiencies in the code of climate models?',\n",
       " 'output': 'The State of the Union address mentions the need to address climate change and promote environmental justice, while Ruff could help detect inefficiencies in the code of climate models by flagging violations of coding best practices and catching potential errors or bugs.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What does the State of the Union address say about climate change? How could Ruff help detect inefficiencies in the code of climate models?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07938d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff is a python linter, so it likely has features that are specific to code quality and may not be relevant to healthcare. The State of the Union address may mention healthcare, but it is unlikely to provide specific information about Ruff's capabilities.\n",
      "Action: Ruff QA System\n",
      "Action Input: What does Ruff do better than Flake8?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff implements more rules than Flake8 and can be used as a drop-in replacement for Flake8 when used with a small number of plugins, alongside Black, and on Python 3 code. It also re-implements popular Flake8 plugins natively and can automatically fix its own lint violations.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information does not directly answer the question about healthcare, but it does provide insight into Ruff's capabilities.\n",
      "Action: State of Union QA System\n",
      "Action Input: What does the State of the Union address say about healthcare?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The State of the Union address mentions a plan to supercharge the Cancer Moonshot and calls on Congress to fund ARPA-H, a project aimed at driving breakthroughs in cancer, Alzheimer's, diabetes, and more. It also mentions a crackdown on companies overcharging American businesses and consumers, and setting higher standards for nursing homes to ensure quality care for loved ones. Additionally, it mentions providing more training and apprenticeships for workers and increasing support for HBCUs and community colleges.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information does not directly mention Ruff or its capabilities, but it does provide insight into the current state of healthcare in the United States.\n",
      "Action: Ruff QA System\n",
      "Action Input: Can Ruff improve code quality in medical applications?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know. Ruff is a linter and formatter for Python code, so it can help improve the quality of Python code in general. However, it is not specifically designed for medical applications, so it may not have any specific features or rules that would improve code quality in that context. It would be best to consult with a medical professional or software engineer with experience in medical applications to determine the best tools and practices for improving code quality in that specific field.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This answer provides some insight into Ruff's capabilities in the context of medical applications, but it is not a definitive answer.\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: Ruff is a python linter that can help improve code quality in general, but it may not have specific features or rules for medical applications. The State of the Union address mentions plans for improving healthcare in the United States, but it does not directly mention Ruff or its capabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does Ruff do better than Flake8? What does the State of the Union address say about healthcare? And can Ruff improve code quality in medical applications?',\n",
       " 'output': 'Ruff is a python linter that can help improve code quality in general, but it may not have specific features or rules for medical applications. The State of the Union address mentions plans for improving healthcare in the United States, but it does not directly mention Ruff or its capabilities.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What does Ruff do better than Flake8? What does the State of the Union address say about healthcare? And can Ruff improve code quality in medical applications?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

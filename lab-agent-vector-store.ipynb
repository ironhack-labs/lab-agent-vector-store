{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
    "\n",
    "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.5-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (2.10.6)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.21.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.21.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.68.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Using cached langchain_core-0.3.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_community) (3.11.13)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
      "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.19.0->chromadb) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-1.0.5-cp39-abi3-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/18.2 MB 1.6 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.3/18.2 MB 1.6 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.6/18.2 MB 1.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 2.1/18.2 MB 1.8 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 1.8 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 2.9/18.2 MB 1.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 3.4/18.2 MB 1.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 3.9/18.2 MB 1.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 4.2/18.2 MB 1.9 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 4.7/18.2 MB 1.9 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 5.0/18.2 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 5.5/18.2 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 6.0/18.2 MB 2.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 6.6/18.2 MB 2.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 7.1/18.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 7.6/18.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 7.9/18.2 MB 2.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 8.4/18.2 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 8.9/18.2 MB 2.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 9.4/18.2 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 10.0/18.2 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 11.0/18.2 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 11.8/18.2 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 12.3/18.2 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 13.4/18.2 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 14.2/18.2 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 14.7/18.2 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 15.2/18.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 15.7/18.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 16.5/18.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.0/18.2 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.6/18.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Using cached langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "Downloading langchain_openai-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.9 MB/s eta 0:00:00\n",
      "Using cached langchain_core-0.3.52-py3-none-any.whl (433 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langsmith-0.3.31-py3-none-any.whl (358 kB)\n",
      "Downloading mmh3-5.1.0-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.21.0-cp311-cp311-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.8 MB 2.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/11.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.8 MB 3.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/11.8 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/11.8 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.2/11.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.0/11.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.8/11.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/11.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.7/11.8 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "   ---------------------------------------- 0.0/647.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 647.0/647.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
      "Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Using cached sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl (295 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading watchfiles-1.0.5-cp311-cp311-win_amd64.whl (291 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53914 sha256=8b64ca1ce8ac270071d836903068990af060f918d9f51e92dca94b977f8e68c7\n",
      "  Stored in directory: c:\\users\\azams\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, zstandard, zipp, websockets, websocket-client, shellingham, pyreadline3, pyproject_hooks, pyasn1, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, oauthlib, mypy-extensions, mmh3, marshmallow, jsonpointer, importlib-resources, httpx-sse, httptools, greenlet, googleapis-common-protos, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, SQLAlchemy, rsa, requests-toolbelt, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-exporter-otlp-proto-common, jsonpatch, importlib-metadata, humanfriendly, build, typer, pydantic-settings, opentelemetry-api, openai, langsmith, google-auth, fastapi, dataclasses-json, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, langchain-core, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, langchain-text-splitters, langchain_openai, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain, opentelemetry-instrumentation-fastapi, langchain_community, chromadb\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.66.5\n",
      "    Uninstalling openai-1.66.5:\n",
      "      Successfully uninstalled openai-1.66.5\n",
      "Successfully installed SQLAlchemy-2.0.40 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.9 google-auth-2.39.0 googleapis-common-protos-1.70.0 greenlet-3.2.0 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-32.0.1 langchain-0.3.23 langchain-core-0.3.52 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_openai-0.3.13 langsmith-0.3.31 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mypy-extensions-1.0.0 oauthlib-3.2.2 onnxruntime-1.21.0 openai-1.75.0 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 orjson-3.10.16 overrides-7.7.0 posthog-3.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-settings-2.8.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.45.3 tiktoken-0.9.0 typer-0.15.2 typing-inspect-0.9.0 uvicorn-0.34.1 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 zipp-3.21.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\azams\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb langchain langchain_community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're using colab, run this\n",
    "#os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "doc_path = str(Path(*relevant_parts) / \"sonnets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2675861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azams\\AppData\\Local\\Temp\\ipykernel_7940\\3499451886.py:12: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  docsearch.persist()\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "sonnets_db_path = \"chroma_sonnets\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    persist_directory=sonnets_db_path\n",
    ")\n",
    "docsearch.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sonnets = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6022759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\azams\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.4 soupsieve-2.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\azams\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2122, which is longer than the specified 1000\n",
      "Created a chunk of size 3187, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1256, which is longer than the specified 1000\n",
      "Created a chunk of size 2321, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "ruff_db_path = \"chroma_ruff\"\n",
    "ruff_db = Chroma.from_documents(\n",
    "    ruff_texts,\n",
    "    embeddings,\n",
    "    persist_directory=ruff_db_path\n",
    ")\n",
    "ruff_db.persist()\n",
    "ruff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description=\"Ask about the content of Shakespeare's sonnets.\"\n",
    "        ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azams\\AppData\\Local\\Temp\\ipykernel_7940\\1834837320.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to answer this question.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is the theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try rephrasing the question.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is the main idea of Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know, this context is about a linter called Ruff and its comparison to other tools. It doesn't mention anything about Sonnet 18.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the main idea of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the central message of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the main theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the overall message of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the main point of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the main idea of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is the main idea of Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know, this context is about a linter called Ruff and its comparison to other tools. It doesn't mention anything about Sonnet 18.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the main theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is the main theme of Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What is the central message of Sonnet 18?\"\u001b[0m\n",
      "Observation: Sonnets QA System is not a valid tool, try one of [sonnets QA System, Ruff QA System].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using a different tool.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What is the central message of Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the theme of Sonnet 18?',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What is the theme of Sonnet 18?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff and flake8 are both python linters, so they have similar functions. However, there may be specific reasons why one would be preferred over the other.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and yesqa, while Flake8 may have conflicts with these tools.\n",
      "\n",
      "3. Automatic fixing of lint violations: Ruff is capable of automatically fixing its own lint violations, while Flake8 does not have this capability.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff natively implements some of the most popular Flake8 plugins, making it more efficient and less prone to conflicts.\n",
      "\n",
      "5. Can be used as a formatter: Ruff can be used as a formatter, making it a more versatile tool than Flake8.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and efficient solution for code linting compared to Flake8.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, native implementation of popular Flake8 plugins, and can be used as a formatter, making it a more comprehensive and efficient solution for code linting compared to Flake8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': 'Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, native implementation of popular Flake8 plugins, and can be used as a formatter, making it a more comprehensive and efficient solution for code linting compared to Flake8.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description= \"Ask about the content of Shakespeare's sonnets.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What does the poet compare his beloved to in Sonnet 18?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The poet compares his beloved to a summer's day.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What does the poet compare his beloved to in Sonnet 18?',\n",
       " 'output': \" The poet compares his beloved to a summer's day.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What does the poet compare his beloved to in Sonnet 18?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff and flake8 are both python linters, so they have similar functions. However, there may be specific reasons why one would be preferred over the other.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\n",
      "\n",
      "3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff re-implements some of the most popular Flake8 plugins natively, which means you don't have to install and configure multiple plugins to get the same functionality.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and user-friendly experience compared to Flake8, making it a popular choice for many developers.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': \"\\nThere are a few reasons why someone might choose to use Ruff over Flake8:\\n\\n1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\\n\\n2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\\n\\n3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\\n\\n4. Native implementation of popular Flake8 plugins: Ruff re-implements some of the most popular Flake8 plugins natively, which means you don't have to install and configure multiple plugins to get the same functionality.\\n\\nOverall, Ruff offers a more comprehensive and user-friendly experience compared to Flake8, making it a popular choice for many developers.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to answer the first question and the Sonnets QA System to answer the second question.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What tool does Ruff use to lint Jupyter Notebooks?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff uses nbQA, a tool for running linters and code formatters over Jupyter Notebooks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should now use the Sonnets QA System to answer the second question.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"Did Shakespeare mention nbQA in his sonnets?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m No, Shakespeare did not mention nbQA in his sonnets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Shakespeare did not mention nbQA in his sonnets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Which tool does Ruff use to lint Jupyter Notebooks? Also, did Shakespeare mention that tool in his sonnets?',\n",
       " 'output': 'Shakespeare did not mention nbQA in his sonnets.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"Which tool does Ruff use to lint Jupyter Notebooks? Also, did Shakespeare mention that tool in his sonnets?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43635cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine **agents** and **vector stores**. The use case for this is that you've **ingested your data into a vector store and want to interact with it** in an agentic manner.\n",
    "\n",
    "The **recommended method** for doing so is to create a `RetrievalQA` and then **use that as a tool** in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and **use the agent as a way to route between them**. There are two different ways of doing this - you can either **let the agent use the vector stores as normal tools**, or you can **set `return_direct=True` to really just use the agent as a router**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'seed': None, 'logprobs': None, 'max_tokens': 256}\n",
      "<class 'langchain_openai.llms.base.OpenAI'>\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature = 0)\n",
    "\n",
    "print(llm)\n",
    "print(type(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "\n",
    "doc_path = str(Path(*relevant_parts) / \"state_of_the_union.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2675861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name = \"state-of-union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_of_union = RetrievalQA.from_chain_type(\n",
    "    llm = llm, chain_type = \"stuff\", retriever = docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2122, which is longer than the specified 1000\n",
      "Created a chunk of size 3187, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1256, which is longer than the specified 1000\n",
      "Created a chunk of size 1051, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "\n",
    "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name = \"ruff\")\n",
    "\n",
    "ruff = RetrievalQA.from_chain_type(\n",
    "    llm = llm, chain_type = \"stuff\", retriever = ruff_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"State of Union QA System\",\n",
    "        func = state_of_union.run,\n",
    "        description = \"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Ruff QA System\",\n",
    "        func = ruff.run,\n",
    "        description = \"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44355/2362715253.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \"Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff is a python linter, so it may have different features and capabilities compared to flake8.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and type checkers like Mypy. This means that you can use Ruff alongside these tools to get more comprehensive feedback on your code.\n",
      "\n",
      "3. Automatic fixing of lint violations: Unlike Flake8, Ruff is capable of automatically fixing its own lint violations. This can save you time and effort when fixing issues in your code.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff natively implements some of the most popular Flake8 plugins, which means you don't have to install and configure them separately.\n",
      "\n",
      "5. More customizable configuration: Ruff allows for more customizable configuration through its TOML configuration file. This can be helpful for tailoring the linter to your specific needs.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and customizable linting experience compared to Flake8.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, native implementation of popular Flake8 plugins, and more customizable configuration compared to Flake8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': 'Ruff offers a larger rule set, better compatibility with other tools, automatic fixing of lint violations, native implementation of popular Flake8 plugins, and more customizable configuration compared to Flake8.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"State of Union QA System\",\n",
    "        func = state_of_union.run,\n",
    "        description = \"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "        return_direct = True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Ruff QA System\",\n",
    "        func = ruff.run,\n",
    "        description = \"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "        return_direct = True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
      "Action: State of Union QA System\n",
      "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
       " 'output': \" Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Ruff is a python linter, so it may have different features and capabilities compared to flake8.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "There are a few reasons why someone might choose to use Ruff over Flake8:\n",
      "\n",
      "1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\n",
      "\n",
      "2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and yesqa, while Flake8 may have conflicts with these tools.\n",
      "\n",
      "3. Automatic fixing of lint violations: Ruff has the ability to automatically fix some of its own lint violations, while Flake8 does not have this feature.\n",
      "\n",
      "4. Native implementation of popular Flake8 plugins: Ruff natively implements some of the most popular Flake8 plugins, making it more efficient and less prone to conflicts.\n",
      "\n",
      "5. Can be used as a formatter: Ruff can be used as a formatter, making it a one-stop solution for both linting and formatting your code.\n",
      "\n",
      "Overall, Ruff offers a more comprehensive and efficient solution for code quality and can be a better choice for those looking for a more robust linter.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': '\\nThere are a few reasons why someone might choose to use Ruff over Flake8:\\n\\n1. Larger rule set: Ruff implements over 800 rules, while Flake8 only implements around 200. This means that Ruff can catch more potential issues in your code.\\n\\n2. Better compatibility with other tools: Ruff is designed to work well with other tools like Black, isort, and yesqa, while Flake8 may have conflicts with these tools.\\n\\n3. Automatic fixing of lint violations: Ruff has the ability to automatically fix some of its own lint violations, while Flake8 does not have this feature.\\n\\n4. Native implementation of popular Flake8 plugins: Ruff natively implements some of the most popular Flake8 plugins, making it more efficient and less prone to conflicts.\\n\\n5. Can be used as a formatter: Ruff can be used as a formatter, making it a one-stop solution for both linting and formatting your code.\\n\\nOverall, Ruff offers a more comprehensive and efficient solution for code quality and can be a better choice for those looking for a more robust linter.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"State of Union QA System\",\n",
    "        func = state_of_union.run,\n",
    "        description = \"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Ruff QA System\",\n",
    "        func = ruff.run,\n",
    "        description = \"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should check both tools to see if they have any information on Jupyter Notebooks.\n",
      "Action: Ruff QA System\n",
      "Action Input: What tool does ruff use to run over Jupyter Notebooks?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff does not currently have a specific tool for running over Jupyter Notebooks. However, it is possible to use Ruff with Jupyter Notebooks by converting the notebook to a Python script and then running Ruff on the script.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should also check the State of Union QA System to see if the president mentioned any tools related to Jupyter Notebooks.\n",
      "Action: State of Union QA System\n",
      "Action Input: Did the president mention any tools related to Jupyter Notebooks in the state of the union?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m No, the president did not mention any tools related to Jupyter Notebooks in the state of the union.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know that neither Ruff nor the president mentioned a specific tool for running over Jupyter Notebooks.\n",
      "Final Answer: Neither Ruff nor the president mentioned a specific tool for running over Jupyter Notebooks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?',\n",
       " 'output': 'Neither Ruff nor the president mentioned a specific tool for running over Jupyter Notebooks.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
    "\n",
    "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (2.9.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (0.115.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.19.2-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (0.20.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.67.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (3.10.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Using cached tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.40.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: sympy in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (75.1.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.26.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.24.0-cp310-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-13.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\katha\\anaconda3\\envs\\langchain\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.5.15-py3-none-any.whl (607 kB)\n",
      "   ---------------------------------------- 0.0/607.0 kB ? eta -:--:--\n",
      "   --------------------------------- ----- 524.3/607.0 kB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 607.0/607.0 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.67.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.0 MB/s eta 0:00:00\n",
      "Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Downloading mmh3-5.0.1-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading onnxruntime-1.19.2-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 6.8/11.1 MB 34.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 31.5 MB/s eta 0:00:00\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rich-13.9.3-py3-none-any.whl (242 kB)\n",
      "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tomli-2.0.2-py3-none-any.whl (13 kB)\n",
      "Downloading watchfiles-0.24.0-cp310-none-win_amd64.whl (277 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-13.1-cp310-cp310-win_amd64.whl (159 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53836 sha256=780af0ff86b7a755869654427999c614e6a60b0ae09d741d1e638081ada8255c\n",
      "  Stored in directory: c:\\users\\katha\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, wrapt, websockets, websocket-client, tomli, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, importlib-metadata, httptools, grpcio, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, humanfriendly, googleapis-common-protos, deprecated, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, coloredlogs, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.5.0\n",
      "    Uninstalling importlib_metadata-8.5.0:\n",
      "      Successfully uninstalled importlib_metadata-8.5.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.15 coloredlogs-15.0.1 deprecated-1.2.14 durationpy-0.9 flatbuffers-24.3.25 google-auth-2.35.0 googleapis-common-protos-1.65.0 grpcio-1.67.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.7.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.3 rsa-4.9 shellingham-1.5.4 tomli-2.0.2 typer-0.12.5 watchfiles-0.24.0 websocket-client-1.8.0 websockets-13.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "#HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "doc_path = str(Path(*relevant_parts) / \"sonnets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2675861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"sonnets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sonnets = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2130, which is longer than the specified 1000\n",
      "Created a chunk of size 3187, which is longer than the specified 1000\n",
      "Created a chunk of size 1256, which is longer than the specified 1000\n",
      "Created a chunk of size 1051, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
    "ruff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description=\"useful for when you need to answer questions about Shakespeare and his sonnets. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katha\\AppData\\Local\\Temp\\ipykernel_14540\\1834837320.py:3: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Shakespeare is known for his sonnets about love, so the Sonnets QA System would likely be the best tool to use.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What did Shakespeare say about love?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Shakespeare believed that true love is constant and unchanging, and that it can withstand the test of time and any obstacles that may come its way. He also believed that love should not be based on superficial things like physical appearance, but rather on a deep and unwavering connection between two people.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This answer aligns with Shakespeare's famous quote, \"Love looks not with the eyes, but with the mind.\"\n",
      "Final Answer: Shakespeare believed that true love is constant and unchanging, and that it should be based on a deep and unwavering connection between two people rather than superficial things like physical appearance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did Shakespeare say about love?',\n",
       " 'output': 'Shakespeare believed that true love is constant and unchanging, and that it should be based on a deep and unwavering connection between two people rather than superficial things like physical appearance.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did Shakespeare say about love?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m It's important to understand the differences between tools before deciding which one to use.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the differences between ruff and flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff implements more rules than Flake8 and does not support custom lint rules. It also has some minor differences in its rule set and does not include all of the 'opinionated' rules from flake8-bugbear. Additionally, Ruff is capable of automatically fixing its own lint violations, while Flake8 supports plugins and allows for custom and third-party rules.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems like Ruff may be a more comprehensive and customizable linter.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the benefits of using Ruff?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "Some potential benefits of using Ruff include:\n",
      "\n",
      "1. Compatibility with Black: Ruff is designed to be used alongside Black, making it easy to use both tools together for consistent code formatting.\n",
      "\n",
      "2. Large rule set: Ruff implements over 800 rules, making it a comprehensive linter for Python code.\n",
      "\n",
      "3. Automatic fixing: Ruff is capable of automatically fixing some of its own lint violations, saving time and effort for developers.\n",
      "\n",
      "4. Drop-in replacement for other tools: Ruff can be used as a drop-in replacement for Flake8 and some of its popular plugins, making it easy to switch to Ruff without losing functionality.\n",
      "\n",
      "5. Integration with type checkers: Ruff can be used in conjunction with type checkers like Mypy, Pyright, or Pyre, providing complementary feedback on code errors and issues.\n",
      "\n",
      "6. Easy to install: Ruff is available on PyPI and can be installed with a simple pip command, without the need for additional dependencies like Rust.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Ruff seems like a powerful and versatile tool for linting Python code.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the limitations of using Ruff?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff's primary limitation is that it does not support custom lint rules. It also may yield slightly different results than other tools such as Pylint or Flake8.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It's important to consider these limitations when deciding whether to use Ruff or another linter.\n",
      "Final Answer: Ruff may be a more comprehensive and customizable linter, but it does have limitations such as not supporting custom lint rules. It's important to weigh these factors when deciding whether to use Ruff or another tool like Flake8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': \"Ruff may be a more comprehensive and customizable linter, but it does have limitations such as not supporting custom lint rules. It's important to weigh these factors when deciding whether to use Ruff or another tool like Flake8.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description=\"useful for when you need to answer questions about Shakespeare and his sonnets. Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Shakespeare is known for his sonnets about love, so the Sonnets QA System would likely be the best tool to use.\n",
      "Action: Sonnets QA System\n",
      "Action Input: \"What did Shakespeare say about love?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Shakespeare believed that true love is constant and unchanging, and that it can withstand the test of time and any obstacles that may come its way. He also believed that love should not be based on superficial things like physical appearance, but rather on a deep and unwavering connection between two people.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did Shakespeare say about love?',\n",
       " 'output': ' Shakespeare believed that true love is constant and unchanging, and that it can withstand the test of time and any obstacles that may come its way. He also believed that love should not be based on superficial things like physical appearance, but rather on a deep and unwavering connection between two people.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What did Shakespeare say about love?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m It's important to understand the differences between different tools before deciding which one to use.\n",
      "Action: Ruff QA System\n",
      "Action Input: \"What are the differences between ruff and flake8?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff implements more rules than Flake8 and does not support custom lint rules. It also has some minor differences in its rule set and does not include all of the 'opinionated' rules from flake8-bugbear. Additionally, Ruff is capable of automatically fixing its own lint violations, while Flake8 supports plugins and allows for custom and third-party rules.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why use ruff over flake8?',\n",
       " 'output': \" Ruff implements more rules than Flake8 and does not support custom lint rules. It also has some minor differences in its rule set and does not include all of the 'opinionated' rules from flake8-bugbear. Additionally, Ruff is capable of automatically fixing its own lint violations, while Flake8 supports plugins and allows for custom and third-party rules.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Why use ruff over flake8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Sonnets QA System\",\n",
    "        func=sonnets.run,\n",
    "        description=\"useful for when you need to answer questions about Shakespeare and his sonnets. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to answer the first question and the Sonnets QA System to answer the second question.\n",
      "Action: Ruff QA System\n",
      "Action Input: What tool does ruff use to run over Jupyter Notebooks?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff does not currently support Jupyter Notebooks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try asking about Jupyter Notebooks in the Sonnets QA System.\n",
      "Action: Sonnets QA System\n",
      "Action Input: Did Shakespeare mention Jupyter Notebooks in his sonnets?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m No, Shakespeare did not mention Jupyter Notebooks in his sonnets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try asking about tools in general in the Sonnets QA System.\n",
      "Action: Sonnets QA System\n",
      "Action Input: Did Shakespeare mention any tools in his sonnets?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m No, Shakespeare does not mention any tools in his sonnets.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: No, Shakespeare did not mention any tools in his sonnets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What tool does ruff use to run over Jupyter Notebooks? Did Shakespeare mention that tool in his sonnets?',\n",
       " 'output': 'No, Shakespeare did not mention any tools in his sonnets.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What tool does ruff use to run over Jupyter Notebooks? Did Shakespeare mention that tool in his sonnets?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
